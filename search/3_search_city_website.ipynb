{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T12:53:53.580605Z",
     "start_time": "2025-09-10T12:53:51.594022Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import csv\n",
    "from googleapiclient.discovery import build\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.datavalidation import DataValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T12:53:55.460596Z",
     "start_time": "2025-09-10T12:53:55.431045Z"
    }
   },
   "outputs": [],
   "source": [
    "eu = pd.read_csv(\"eu_checked20250826.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T12:53:59.988208Z",
     "start_time": "2025-09-10T12:53:59.959538Z"
    }
   },
   "outputs": [],
   "source": [
    "eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T12:54:02.173546Z",
     "start_time": "2025-09-10T12:54:02.163242Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in API key and case ID\n",
    "api_key = open('api_key.txt', 'r').read().strip()\n",
    "case_id = open('case_id.txt', 'r').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T12:54:03.493380Z",
     "start_time": "2025-09-10T12:54:03.474409Z"
    }
   },
   "outputs": [],
   "source": [
    "def google(search_term, api_key, case_id):\n",
    "    \"\"\"\n",
    "    Use Google Custom Search API to collect search results.\n",
    "    \n",
    "    Args:\n",
    "        search_term: search string. The maximium length is 2048 characters.\n",
    "        api_key: api key.\n",
    "        case_id: case_id.\n",
    "    Returns:\n",
    "        titlel: the title of each returned search result.\n",
    "        linkl: the link of each returned search result.\n",
    "        snippetl: the snippet of each returned search result.\n",
    "    \"\"\"\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "    result = service.cse().list(q=search_term, cx=case_id).execute()\n",
    "    est_total_num = int(result[\"searchInformation\"][\"totalResults\"])\n",
    "    titlel = []\n",
    "    linkl = []\n",
    "    snippetl = []\n",
    "    if est_total_num == 0:\n",
    "        return titlel, linkl, snippetl\n",
    "    elif est_total_num <= 10:\n",
    "        for item in result.get(\"items\", []):\n",
    "            titlel.append(item[\"title\"])\n",
    "            linkl.append(item[\"link\"])\n",
    "            snippetl.append(item['snippet'])\n",
    "        return titlel, linkl, snippetl\n",
    "    else:\n",
    "        for item in result.get(\"items\", []):\n",
    "            titlel.append(item[\"title\"])\n",
    "            linkl.append(item[\"link\"])\n",
    "            snippetl.append(item['snippet'])\n",
    "        total_page = math.ceil(est_total_num/10)\n",
    "        if total_page > 10:\n",
    "            total_page = 10\n",
    "        for page in range(1, total_page):\n",
    "            start = page * 10 + 1\n",
    "            more_result = service.cse().list(q=search_term, cx=case_id, start=start).execute()\n",
    "            new_total_num = int(more_result[\"searchInformation\"][\"totalResults\"])\n",
    "            if new_total_num == 0:\n",
    "                return titlel, linkl, snippetl\n",
    "            else:\n",
    "                for item in more_result.get(\"items\", []):\n",
    "                    titlel.append(item[\"title\"])\n",
    "                    linkl.append(item[\"link\"])\n",
    "                    snippetl.append(item['snippet'])\n",
    "        return titlel, linkl, snippetl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T13:26:37.837526Z",
     "start_time": "2025-09-10T13:26:37.827341Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the output file name\n",
    "today_str = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "filename = f\"data/cityweb{today_str}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T13:26:45.877926Z",
     "start_time": "2025-09-10T13:26:45.866332Z"
    }
   },
   "outputs": [],
   "source": [
    "# Controls for subset selection\n",
    "TEST_LIMIT = None         \n",
    "START_AT = 470              \n",
    "SLEEP_BETWEEN_CITIES = 1.0 \n",
    "SLEEP_ON_ERROR = 60        \n",
    "VERBOSE = True\n",
    "\n",
    "# define date and ID counter\n",
    "idx = 5816\n",
    "date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T13:53:36.878328Z",
     "start_time": "2025-09-10T13:26:51.858805Z"
    }
   },
   "outputs": [],
   "source": [
    "subset = eu.iloc[START_AT: START_AT + TEST_LIMIT] if TEST_LIMIT else eu.iloc[START_AT:]\n",
    "total_rows = len(subset)\n",
    "\n",
    "print(f\"Starting city web search on {total_rows} row(s). Output -> {filename}\", flush=True)\n",
    "\n",
    "results_written = 0\n",
    "\n",
    "with open(filename, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for row_idx, (_, row) in enumerate(subset.iterrows(), start=1):\n",
    "        domain = \"\"\n",
    "        try:\n",
    "            keyword = str(row.get(\"ai_translate\", \"\")).strip()\n",
    "            source_url = str(row.get(\"City_Website\", \"\")).strip()\n",
    "\n",
    "            # record city/state/country exactly as in the original file\n",
    "            city_val = str(row.get(\"City_Name\", \"\"))\n",
    "            state_val = str(row.get(\"State\", \"\"))\n",
    "            country_val = str(row.get(\"Country_Name\", \"\"))\n",
    "\n",
    "            # basic validation\n",
    "            if not keyword or not source_url:\n",
    "                if VERBOSE:\n",
    "                    print(f\"[{row_idx}/{total_rows}] Skipping (missing keyword or City_Website) — {city_val}, {state_val}, {country_val}\", flush=True)\n",
    "                time.sleep(SLEEP_BETWEEN_CITIES)\n",
    "                continue\n",
    "\n",
    "            parsed = urlparse(source_url)\n",
    "            domain = parsed.netloc + parsed.path if parsed.netloc else re.sub(r'^https?://', '', source_url).strip('/')\n",
    "            if not domain:\n",
    "                if VERBOSE:\n",
    "                    print(f\"[{row_idx}/{total_rows}] Skipping (invalid domain) — {city_val}, {state_val}, {country_val} — raw: {source_url}\", flush=True)\n",
    "                time.sleep(SLEEP_BETWEEN_CITIES)\n",
    "                continue\n",
    "\n",
    "            search_term = f'\"{keyword}\" site:{domain}'\n",
    "\n",
    "            if VERBOSE:\n",
    "                print(f\"[{row_idx}/{total_rows}] {city_val}, {state_val}, {country_val} | domain={domain} | query='{search_term}'\", flush=True)\n",
    "\n",
    "            titlel, linkl, snippetl = google(search_term, api_key, case_id)\n",
    "            if VERBOSE:\n",
    "                print(f\"    -> {len(titlel)} result(s)\", flush=True)\n",
    "\n",
    "            if len(titlel) == 0:\n",
    "                time.sleep(SLEEP_BETWEEN_CITIES)\n",
    "                continue\n",
    "\n",
    "            for title, link, snippet in zip(titlel, linkl, snippetl):\n",
    "                id_str = f'cityweb{idx:06d}'\n",
    "                hyperlink = f'=HYPERLINK(\"{link}\", \"{link}\")'\n",
    "                writer.writerow([id_str, date_str, city_val, state_val, country_val, title, snippet, hyperlink])\n",
    "                idx += 1\n",
    "                results_written += 1\n",
    "\n",
    "            time.sleep(SLEEP_BETWEEN_CITIES)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{row_idx}/{total_rows}] Error for {city_val}, {state_val}, {country_val} (domain={domain or 'unknown'}): {e} — sleeping {SLEEP_ON_ERROR}s then retrying once\", flush=True)\n",
    "            time.sleep(SLEEP_ON_ERROR)\n",
    "            # retry once\n",
    "            try:\n",
    "                titlel, linkl, snippetl = google(search_term, api_key, case_id)\n",
    "                if VERBOSE:\n",
    "                    print(f\"    (retry) -> {len(titlel)} result(s)\", flush=True)\n",
    "                for title, link, snippet in zip(titlel, linkl, snippetl):\n",
    "                    id_str = f'cityweb{idx:06d}'\n",
    "                    hyperlink = f'=HYPERLINK(\"{link}\", \"{link}\")'\n",
    "                    writer.writerow([id_str, date_str, city_val, state_val, country_val, title, snippet, hyperlink])\n",
    "                    idx += 1\n",
    "                    results_written += 1\n",
    "                print(\"    (retry) Done\", flush=True)\n",
    "                time.sleep(SLEEP_BETWEEN_CITIES)\n",
    "            except Exception as e2:\n",
    "                print(f\"    (retry) failed: {e2}\", flush=True)\n",
    "\n",
    "print(f\"Finished. Wrote {results_written} row(s) to {filename}.\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:23.918427Z",
     "start_time": "2025-09-10T14:20:23.895671Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename, names=[\"id\", \"search_date\",\"city\",\"state\",\"country\",\"link_title\",\"link_des\",\"link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:24.564684Z",
     "start_time": "2025-09-10T14:20:24.540425Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"link\"] = df[\"link\"].str.extract(r'HYPERLINK\\(\"([^\"]+)\"')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:25.293773Z",
     "start_time": "2025-09-10T14:20:25.272962Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:26.107047Z",
     "start_time": "2025-09-10T14:20:26.090804Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare for coding\n",
    "new_cols = [\n",
    "    \"inaccessible\",\n",
    "    \"irrelevant\",\n",
    "    \"year\",\n",
    "    \"use_case\",\n",
    "    \"mode\",\n",
    "    \"motivation\",\n",
    "    \"stakeholder\",\n",
    "    \"detail\",\n",
    "    \"note\",\n",
    "    \"other_ref\",\n",
    "    \"coder\"\n",
    "]\n",
    "\n",
    "for col in new_cols:\n",
    "    df[col] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:26.973864Z",
     "start_time": "2025-09-10T14:20:26.960752Z"
    }
   },
   "outputs": [],
   "source": [
    "# reorder\n",
    "df = df[[\"id\",\"search_date\",\"link_title\",\"link_des\",\"link\",\n",
    "         \"inaccessible\",\"irrelevant\",\n",
    "         \"city\",\"state\",\"country\",\n",
    "         \"year\",\"use_case\",\"mode\",\"motivation\",\"stakeholder\",\"detail\",\"note\",\"other_ref\",\"coder\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:27.566767Z",
     "start_time": "2025-09-10T14:20:27.542437Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:28.465185Z",
     "start_time": "2025-09-10T14:20:28.269855Z"
    }
   },
   "outputs": [],
   "source": [
    "filename_check = filename.replace(\".csv\", \"_check.xlsx\")\n",
    "df.to_excel(filename_check, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:33.542780Z",
     "start_time": "2025-09-10T14:20:33.314805Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up the mode coding options\n",
    "wb = load_workbook(filename_check)\n",
    "ws = wb[\"Sheet1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:34.116407Z",
     "start_time": "2025-09-10T14:20:34.106070Z"
    }
   },
   "outputs": [],
   "source": [
    "dv = DataValidation(\n",
    "    type=\"list\",\n",
    "    formula1='\"road,rail,air,waterborne,cross_modal\"',\n",
    "    allow_blank=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:34.951243Z",
     "start_time": "2025-09-10T14:20:34.941215Z"
    }
   },
   "outputs": [],
   "source": [
    "dv.add(\"M2:M10000\")\n",
    "ws.add_data_validation(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T14:20:36.228510Z",
     "start_time": "2025-09-10T14:20:36.091584Z"
    }
   },
   "outputs": [],
   "source": [
    "wb.save(filename_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
